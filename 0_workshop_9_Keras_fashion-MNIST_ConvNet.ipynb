{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<img align=left src='keras.png' width='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zalando dataset: Fashion-Mnist\n",
    "\n",
    "Przyklad oparty na bazie danych Fashion-MNIST czyli zdjęciach z Zalando (60,000 w bazie treningowej i 10,000 testowych).  \n",
    "Każde zdjęcie to czarno-biały obrazek o rozdzielczości 28x28 oraz numer jednej z 10 klas: \n",
    "\n",
    "<img align='left' src='fashion-mnist.png' width='500' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Katergorie w zestawie\n",
    "- 0\tT-shirt/top\n",
    "- 1\tTrouser\n",
    "- 2\tPullover\n",
    "- 3\tDress\n",
    "- 4\tCoat\n",
    "- 5\tSandal\n",
    "- 6\tShirt\n",
    "- 7\tSneaker\n",
    "- 8\tBag\n",
    "- 9\tAnkle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importujemy niezbędne moduły"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ładujemy dane: fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wgrywamy dane i dzielimy ja na training i test set\n",
    "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()\n",
    "\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# katergorie produktów w bazie \n",
    "kategorie = {0:'T-shirt/top', 1: 'Trousers', 2: 'Pullover', 3: 'Dress', 4: 'Coat', \n",
    "             5: 'Sandals', 6:'Shirt', 7:'Sneacker', 8:'Bag', 9:'Ankle boot'}\n",
    "\n",
    "def kategoria(numer):\n",
    "    return kategorie[numer]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_X[24], cmap='gray')\n",
    "print(kategoria(train_Y[24]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zmieniamy kształt danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (60000, 28, 28, 1)\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.reshape(-1, 28,28, 1)\n",
    "test_X = test_X.reshape(-1, 28,28, 1)\n",
    "\n",
    "# zmieniamy dane pixeli na liczby zmiennoprzecinkowe\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "\n",
    "# skalujemy wartosci pixeli do zakresu od 0 do 1\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    "\n",
    "print('train_X shape:', train_X.shape)\n",
    "print(test_X.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zmieniamy odpowiedzi do: one-hot format\n",
    "\n",
    "```\n",
    "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "etc.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# ustalamy ilosc klas\n",
    "num_classes = 10 # ilość klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kategoria: 9, one-hot encoding: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "kategoria: 0, one-hot encoding: [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "kategoria: 3, one-hot encoding: [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "for i in (0,1,3):\n",
    "    print(f'kategoria: {train_Y[i]}, one-hot encoding: {train_Y_one_hot[i]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dzielimy dane na treningowe i walidacyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definiujemy model sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = Sequential()\n",
    "\n",
    "# Kernel (filtr) o rozmiarze (3, 3) Funkcja aktywacyjna, w tym wypadku LeakyReLU\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3), padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "fashion_model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "fashion_model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))                  \n",
    "fashion_model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation='relu'))\n",
    "                  \n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))# Dziękifunkcji  \"softmax\" odpowiedzi są w zakresie [0-1] i sumują się do 1\n",
    "                                                   # czyli mogą być traktowane jako prawdopodobieństwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fashion_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kompilujemy nasz model\n",
    "Nasz model zbudowany w Pythonie jest  optymalizowany i kompilowany do kodu maszynowego. \n",
    "\n",
    "Do skompilowania naszego modelu Keras potrzebuje również **loss function** i **optimizera**. \n",
    "Nasz **loss function** to *categorical crossentropy*, która dobrze nadaje sie do porównywania dwóch rozkładów prawdopodobieństwa.\n",
    "\n",
    "Odpowiedż naszej sieci to prawdopodobieństwo, ze dana cyfra to któraś z 10 cyfr (np. \"na 80% ten obrazek to cyfra '3', na 10% to '8', na 5% to '2', itd\"), a targetem jest dystrybucja w której prawidlłowa odpowiedż ma 100% prawdopodobieństwa, a wszystkie inne odpowiedzi 0%.Cross-entropy jest miarą różnicy pomiędzy naszą dystrybucją prawdopodobieństwa, a prawidłową  \n",
    "[Szczegóły na Wikipedii](https://en.wikipedia.org/wiki/Cross_entropy)\n",
    "\n",
    "Optimizer decyduje, jak szybko model się uczy i zapobiega jego zatrzymaniu.  \n",
    "Korzystamy z ['adama'](http://ruder.io/optimizing-gradient-descent/index.html#adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trenujemy naszą sieć!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametru naszego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # 128 obrazki w jednym mini-batchu, średnia błędów z batcha jest podstawą do zmiany wag w sieci\n",
    "\n",
    "epochs = 10 # ilość epok (ile razy trenujemy sieć używając  naszego zestawu danych)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 121s 3ms/step - loss: 0.5108 - acc: 0.8122 - val_loss: 0.3725 - val_acc: 0.8686\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 113s 2ms/step - loss: 0.3078 - acc: 0.8875 - val_loss: 0.2985 - val_acc: 0.8892\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 126s 3ms/step - loss: 0.2624 - acc: 0.9055 - val_loss: 0.2721 - val_acc: 0.8994\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 134s 3ms/step - loss: 0.2302 - acc: 0.9145 - val_loss: 0.2833 - val_acc: 0.8965\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.2034 - acc: 0.9254 - val_loss: 0.2475 - val_acc: 0.9108\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 137s 3ms/step - loss: 0.1814 - acc: 0.9335 - val_loss: 0.2489 - val_acc: 0.9109\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 131s 3ms/step - loss: 0.1640 - acc: 0.9393 - val_loss: 0.2530 - val_acc: 0.9113\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 130s 3ms/step - loss: 0.1432 - acc: 0.9474 - val_loss: 0.2361 - val_acc: 0.9175\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 122s 3ms/step - loss: 0.1249 - acc: 0.9534 - val_loss: 0.2532 - val_acc: 0.9138\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 126s 3ms/step - loss: 0.1101 - acc: 0.9594 - val_loss: 0.2630 - val_acc: 0.9164\n"
     ]
    }
   ],
   "source": [
    "fashion_train = fashion_model.fit(train_X, train_label, \n",
    "                                  batch_size=batch_size,\n",
    "                                  epochs=10,\n",
    "                                  verbose=1,\n",
    "                                  validation_data=(valid_X, valid_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapisujemy naszą wytrenowaną sieć"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.save('fashion_mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprawdzamy, czy nasza sieć działa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 911us/step\n"
     ]
    }
   ],
   "source": [
    "test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.272498698959\n",
      "Test accuracy: 0.9153\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "def prepare_img(picture_path):\n",
    "    img = image.load_img(path=picture_path,grayscale=True,target_size=(28,28))\n",
    "    img = 255 - image.img_to_array(img)\n",
    "    test_img = img.reshape((1,28,28,1))\n",
    "    return test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trampek = prepare_img('trampek.jpg')\n",
    "shirt_img = prepare_img('shirt2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1722f8a70f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trampek.reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_model.predict(trampek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sneacker'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odp = fashion_model.predict(trampek)\n",
    "kategoria(np.argmax(odp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-47bdeb72a9a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Display the first image in training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m221\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkategoria\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3204\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3205\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   3206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3207\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5485\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    651\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    652\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 653\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(221)\n",
    "plt.imshow(train_X[0], cmap='gray')\n",
    "plt.title(kategoria(train_Y[0]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_X[0], cmap='gray')\n",
    "plt.title(kategoria(test_Y[0]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(223)\n",
    "plt.imshow(train_X[1], cmap='gray')\n",
    "plt.title(kategoria(train_Y[1]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_X[3], cmap='gray')\n",
    "plt.title(kategoria(test_Y[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
